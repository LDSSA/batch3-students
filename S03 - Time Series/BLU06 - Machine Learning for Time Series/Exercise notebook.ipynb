{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3db1b7eb6aade580",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# BLU06  - Exercise Notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d9b262915f7cb1e5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "idx = pd.IndexSlice\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)   \n",
    "from random import seed\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import itertools\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa import stattools\n",
    "import hashlib # for grading purposes\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "from pandas.plotting import lag_plot\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "plt.rcParams['figure.figsize'] = (12, 4)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-efc88f208fd6703c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4b3975b136921032",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def build_target(series_, number_of_periods_ahead):\n",
    "    \"\"\" \n",
    "    takes a series, turned it into a dataframe, and adds a new column called target\n",
    "    This column is the input series, lagged number_of_periods_ahead into the future\n",
    "    \"\"\"\n",
    "    \n",
    "    # make a copy \n",
    "    series_ = series_.copy()\n",
    "    series_.name = 'customers'\n",
    "    \n",
    "    # make a dataframe from the series\n",
    "    df_ = pd.DataFrame(series_)\n",
    "    \n",
    "    # the target column will be the input series, lagged into the future\n",
    "    df_['target'] = series_.shift(-number_of_periods_ahead)\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-922878325abdd03c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def separate_last_day(df_):\n",
    "    \n",
    "    \"\"\"\n",
    "    takes a dataset which has the target and features built \n",
    "    and separates it into the last day\n",
    "    \"\"\"\n",
    "    # take the last period \n",
    "    last_period = df_.iloc[-1]\n",
    "    \n",
    "    # the last period is now a series, so it's name will be the timestamp\n",
    "    training_data = df_.loc[df_.index < last_period.name]\n",
    "\n",
    "    return last_period, training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-84d68d31545e3063",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def build_some_features(df_, num_periods_lagged=1, num_periods_diffed=0, weekday=False, month=False, rolling=[], holidays=False): \n",
    "    \"\"\"\n",
    "    Builds some features by calculating differences between periods  \n",
    "    \"\"\"\n",
    "    # make a copy \n",
    "    df_ = df_.copy()\n",
    "        \n",
    "    # for a few values, get the lags  \n",
    "    for i in range(1, num_periods_lagged+1):\n",
    "        # make a new feature, with the lags in the observed values column\n",
    "        df_['lagged_%s' % str(i)] = df_['customers'].shift(i)\n",
    "        \n",
    "    # for a few values, get the diffs  \n",
    "    for i in range(1, num_periods_diffed+1):\n",
    "        # make a new feature, with the lags in the observed values column\n",
    "        df_['diff_%s' % str(i)] = df_['customers'].diff(i)\n",
    "    \n",
    "    for stat in rolling:\n",
    "        df_['rolling_%s'%str(stat)] = df_['customers'].rolling('7D').aggregate(stat)\n",
    "        \n",
    "    if weekday == True:\n",
    "        df_['sin_weekday'] = np.sin(2*np.pi*df_.index.weekday/7)\n",
    "        df_['cos_weekday'] = np.sin(2*np.pi*df_.index.weekday/7)\n",
    "        \n",
    "    if month == True:\n",
    "        df_['sin_month'] = np.sin(2*np.pi*df_.index.month/12)\n",
    "        df_['cos_month'] = np.sin(2*np.pi*df_.index.month/12)\n",
    "        \n",
    "    if holidays == True:\n",
    "        holidays = df_[((df_.index.month==12) & (df_.index.day==25))\n",
    "              |((df_.index.month==1) & (df_.index.day==1))].customers\n",
    "        df_['holidays'] = holidays + 1\n",
    "        df_['holidays'] = df_['holidays'].fillna(0)\n",
    "    \n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f4d816f5cc808636",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def separate_train_and_test_set(last_period_, training_data_, target='target'): \n",
    "    \n",
    "    \"\"\" \n",
    "    separates training and test set (clue was in the name, really... )\n",
    "    Ok, we were lazy and left the target hardcoded as 'target'. Shame on us. \n",
    "    \"\"\"\n",
    "    \n",
    "    # anything that isn't a target is a feature \n",
    "    features = [feature for feature in training_data_.columns if feature != target]\n",
    "    \n",
    "    # adding a sneaky little dropna to avoid the missing data problem above \n",
    "    X_train = training_data_.dropna()[features]\n",
    "    y_train = training_data_.dropna()[target]\n",
    "    \n",
    "    X_last_period = last_period_[features]\n",
    "    \n",
    "    return X_train, y_train, X_last_period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bc08afac09669562",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def prepare_for_prediction(series_, number_of_periods_ahead, num_periods_lagged, num_periods_diffed, weekday, month, rolling, holidays):\n",
    "    \n",
    "    \"\"\" \n",
    "    Wrapper to go from the original series to X_train, y_train, X_last_period \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # build the target \n",
    "    data_with_target = build_target(series_, \n",
    "                                    number_of_periods_ahead)\n",
    "    \n",
    "    # build the features \n",
    "    data_with_target_and_features = build_some_features(data_with_target, \n",
    "                                                        num_periods_lagged=num_periods_lagged,\n",
    "                                                       num_periods_diffed=num_periods_diffed,\n",
    "                                                       weekday=weekday,\n",
    "                                                       month=month,\n",
    "                                                       rolling=rolling,\n",
    "                                                       holidays=holidays)\n",
    "    # separate train and test data \n",
    "    last_period, training_data = separate_last_day(data_with_target_and_features)\n",
    "\n",
    "    # separate X_train, y_train, and X_test \n",
    "    X_train, y_train, X_last_period = separate_train_and_test_set(last_period, \n",
    "                                                           training_data, \n",
    "                                                           target='target')\n",
    "    \n",
    "    # return ALL OF THE THINGS! (well, actually just the ones we need)\n",
    "    return X_train, y_train, X_last_period "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3a743d99c1cb73f5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def predict_period_n(series_, model, number_of_periods_ahead, num_periods_lagged, num_periods_diffed, weekday, month, rolling, holidays): \n",
    "    \n",
    "        X_train, y_train, X_last_period = prepare_for_prediction(series_, \n",
    "                                                             number_of_periods_ahead, \n",
    "                                                             num_periods_lagged,\n",
    "                                                             num_periods_diffed,\n",
    "                                                             weekday,\n",
    "                                                             month,\n",
    "                                                             rolling,\n",
    "                                                             holidays)\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        return model.predict(X_last_period.values.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2c4345e87909ae7f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def predict_n_periods(series_, n_periods, model, num_periods_lagged, num_periods_diffed=0, weekday=False, month=False,rolling=[], holidays=False): \n",
    "    predictions = []\n",
    "\n",
    "    for period_ahead in range(1, n_periods+1):\n",
    "        pred = predict_period_n(series_=series_, \n",
    "                                model=model, \n",
    "                                number_of_periods_ahead=period_ahead, \n",
    "                                num_periods_lagged=num_periods_lagged,\n",
    "                                num_periods_diffed=num_periods_diffed,\n",
    "                                weekday=weekday,\n",
    "                                month=month,\n",
    "                                rolling=rolling,\n",
    "                                holidays=holidays)\n",
    "        \n",
    "        predictions.append(pred[0])\n",
    "        \n",
    "    return predictions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c9a3e566cc624451",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Let's predict store customers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c89f8456e9e70392",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "store = pd.read_csv('data/stores_exercise.csv')\n",
    "store['date'] = pd.to_datetime(store['date'])\n",
    "store = store.set_index('date')\n",
    "store = store.sort_index()\n",
    "store = store[:-180]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5db0587a41ba75ab",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "##### Plot the series to get an idea of what's going on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-846a66e59e645d8e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "store.plot(figsize=(16, 6));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-50c774b21ff04b4b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Q1: Are there any missing days in the time series? If so, inspect them and decide how to fill them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4673648012938702",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# hint1: if the missing dates are holidays you can fill them with 0, since that's\n",
    "# indication that the store was closed.\n",
    "\n",
    "# hint2: the missing_value_mask should be a boolean Pandas Series with True or False according to if the value\n",
    "# missing or not.\n",
    "\n",
    "# hint3: the missing_value_dates should be a DatetimeIndex with the dates with missing values.\n",
    "\n",
    "# store_resampled = \n",
    "# missing_value_mask =\n",
    "# missing_value_dates = \n",
    "# store_cleaned = \n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-37f19bfc31b2d1e0",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "expected_hash = 'e9f26ecc6d60870d336e555719e6024c19a07e62c9e7174c36c42b847d50936a'\n",
    "assert hashlib.sha256(str(missing_value_dates).encode()).hexdigest() == expected_hash\n",
    "\n",
    "expected_hash = '2fb0b380648291dc9583422cf46dc3b682caaa881b076ff48e4d78f6f26e6898'\n",
    "assert hashlib.sha256(str(store_cleaned).encode()).hexdigest() == expected_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ef1184e061dcce01",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Q2: Formulate it as time series one-step-ahead prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-52ebd77841c0b4ce",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Q2.1 Create the target, 3 lags and drop the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b2bfb6431053bbb1",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# store_features = store_cleaned.copy()\n",
    "# store_features['lag1'] = \n",
    "# store_features['lag2'] = \n",
    "# store_features['lag3'] = \n",
    "# store_features['target'] =\n",
    "# store_features = \n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-ec83e113b13f6716",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "expected_hash = 'a7b263d903e5a6236b7bb778d31fae57462c18f6d888459a9ade11406c1d3729'\n",
    "assert hashlib.sha256(str(store_features.shape).encode()).hexdigest() == expected_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7ab428009d677b3c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Q2.2 Separate the training and test set. The test set consists of the last 60 values, while the training set consists of the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0aa5b9495555cd7d",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# note: this is a very straightforward question. But you may think: \"isn't this one-step-ahead forecasting? \n",
    "# Why does the test have 60 values\" Well, basically this just means we are doing 60 one-step-ahead forecasts.\n",
    "# This way we obtain a better estimate of how our one-step-ahead model would perform in real life.\n",
    "\n",
    "# store_train =\n",
    "# store_test =\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-46d22f610161d58e",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "expected_hash = '0d597dc2afbcf77932523efe4fa118591cbc3f691191c2471ae95e465c918dd3'\n",
    "assert hashlib.sha256(str(store_train.index[-1]).encode()).hexdigest() == expected_hash\n",
    "\n",
    "expected_hash = '23a57d8694a6eb61e0232c384c6939676cf8f8d515298f7f388b9071c22af223'\n",
    "assert hashlib.sha256(str(store_test.index[0]).encode()).hexdigest() == expected_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-328a6be750d6b545",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Q2.3 Fit a linear regression to the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c10406518994a44d",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# X_store_train = \n",
    "# y_store_train =\n",
    "# model =\n",
    "# model.fit()\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-ba2d8a4a2f417e25",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "expected_hash = '0f770c90e52409c91f4805eb0998bb9d76d28ebd9e37a8f6e5c1bc6cc6231081'\n",
    "assert hashlib.sha256(str(X_store_train.shape).encode()).hexdigest() == expected_hash\n",
    "\n",
    "expected_hash = 'b823515f669540cbcf1e9244e5671f14534c9c562175db731e5fb5e4599bbd8c'\n",
    "assert hashlib.sha256(str(y_store_train.shape).encode()).hexdigest() == expected_hash\n",
    "\n",
    "expected_hash = '86875b6d65b929521f16ab8bc45e2fac898ea38ec7746836682655e32eecca7d'\n",
    "assert hashlib.sha256(str(np.round(model.coef_,1)).encode()).hexdigest() == expected_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f91888ec4ca37707",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Q2.4 Predict the test set and calculate the MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c702242ee9013f2d",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# X_store_test =\n",
    "# y_store_test = \n",
    "# y_predict = \n",
    "# test_mae = \n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-fa53ac00c701b6ad",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "expected_hash = 'a838706ef29b226d8f8222bf3d9dac1e28db739da1196180209956ee02da8bae'\n",
    "assert hashlib.sha256(str(X_store_test.shape).encode()).hexdigest() == expected_hash\n",
    "\n",
    "expected_hash = '9053d01727f35cfdbbbd7284dba5e54ee557e5fc33084045dbc6fec2cb8730f7'\n",
    "assert hashlib.sha256(str(y_store_test.shape).encode()).hexdigest() == expected_hash\n",
    "\n",
    "expected_hash = '8c1f1046219ddd216a023f792356ddf127fce372a72ec9b4cdac989ee5b0b455'\n",
    "assert hashlib.sha256(str(np.int(test_mae)).encode()).hexdigest() == expected_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1b64863f837f65e9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Q3 Let's go into multi-step prediction!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b8175f4db9400784",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Q3.1 Separate the data into train and test. Use the _predict_n_periods_ function to predict 60 steps ahead using linear regression. Then, calculate the MAE for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b4e7b5a3887dcbaa",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Use the same number of lags you used in the previous questions. Use no other features.\n",
    "\n",
    "# store_multistep_train = \n",
    "# store_multistep_test =\n",
    "# predictions = \n",
    "# test_mae = \n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-d64221e5c054b60c",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "expected_hash = '299fe0f9c075c40a21029166ce1bd2046db47fcb639a2a13240b5d974961cb0b'\n",
    "assert hashlib.sha256(str(store_multistep_train.shape).encode()).hexdigest() == expected_hash\n",
    "\n",
    "expected_hash = '01f6bb906f864c80f90afb9e7d9071b6f6e7222bf67f2de6bce28f55981fbab4'\n",
    "assert hashlib.sha256(str(store_multistep_test.shape).encode()).hexdigest() == expected_hash\n",
    "\n",
    "expected_hash = 'c010bb0f7f8f335ccb2bc4e598eee48be11f87ac60a39a1a1cb4185688857003'\n",
    "assert hashlib.sha256(str(np.int(predictions[-1])).encode()).hexdigest() == expected_hash\n",
    "\n",
    "expected_hash = 'ad57366865126e55649ecb23ae1d48887544976efea46a48eb5d85a6eeb4d306'\n",
    "assert hashlib.sha256(str(np.int(test_mae)).encode()).hexdigest() == expected_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6cecdca4023a9b09",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Q3.2 Separate into train, val and test. Test corresponds to the last 60 values and Val corresponds to the 60 steps before test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b4676deaf08fb5b8",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# hint: use the cleaned dataset\n",
    "\n",
    "# store_multistep_train =\n",
    "# store_multistep_val =\n",
    "# store_multistep_test = \n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-144aa010340df42d",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "expected_hash = '98eb165d180aa2cd9255f5a5151c101fac78fba9ce6c24421daa8b64ca2a0288'\n",
    "assert hashlib.sha256(str(store_multistep_train.shape).encode()).hexdigest() == expected_hash\n",
    "\n",
    "expected_hash = '01f6bb906f864c80f90afb9e7d9071b6f6e7222bf67f2de6bce28f55981fbab4'\n",
    "assert hashlib.sha256(str(store_multistep_val.shape).encode()).hexdigest() == expected_hash\n",
    "\n",
    "expected_hash = '01f6bb906f864c80f90afb9e7d9071b6f6e7222bf67f2de6bce28f55981fbab4'\n",
    "assert hashlib.sha256(str(store_multistep_test.shape).encode()).hexdigest() == expected_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a252157fed7db039",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Q3.3 Are the day of the week, the month of the year  and one-day diff useful features to the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-16a7b564ac712979",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Create a parameter grid using the gradient boosting regressor as a model. \n",
    "# Use 1 lag, holidays=True and no rollings.\n",
    "# Use random state = 1 for the gradient boosting regressor\n",
    "# Use a for cycle to find the group of params that minimizes the MAE on the validation set.\n",
    "\n",
    "#param_grid = \n",
    "\n",
    "# grid = \n",
    "\n",
    "# for params in grid:\n",
    "     # predictions =\n",
    "                                    \n",
    "# best_params = \n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-27e82c63c7934897",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "expected_hash = '3cbc87c7681f34db4617feaa2c8801931bc5e42d8d0f560e756dd4cd92885f18'\n",
    "assert hashlib.sha256(str(best_params['weekday']).encode()).hexdigest() == expected_hash\n",
    "\n",
    "expected_hash = '3cbc87c7681f34db4617feaa2c8801931bc5e42d8d0f560e756dd4cd92885f18'\n",
    "assert hashlib.sha256(str(best_params['month']).encode()).hexdigest() == expected_hash\n",
    "\n",
    "expected_hash = '6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b'\n",
    "assert hashlib.sha256(str(best_params['num_periods_diffed']).encode()).hexdigest() == expected_hash\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-cd3355c62f859eeb",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Q3.5 Train a model on the test set for the best combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a8fdbd5c2eaf09dc",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# use random_state=1 in the gradient boosting regressor.\n",
    "\n",
    "# store_multistep_train_val = \n",
    "# predictions = \n",
    "# test_mae = \n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-cc1f893477248c54",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "expected_hash = '8241649609f88ccd2a0a5b233a07a538ec313ff6adf695aa44a969dbca39f67d'\n",
    "assert hashlib.sha256(str(np.int(test_mae)).encode()).hexdigest() == expected_hash"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
