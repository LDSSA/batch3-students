{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLU11 - Exercise Notebook\n",
    "\n",
    "## Create your own movie recommender system\n",
    "\n",
    "This exercise notebook will help you create a Recommender System using Collaborative and Content-based filtering and, in the end, it will help you to pick some movies according to your preferences. We will add you as a new user and we will check out what are the best suggestions for you!! üòÄ\n",
    "\n",
    "## Overall Strategy\n",
    "\n",
    "1. **Setup:** Import and preprocess the data\n",
    "1. **Collaborative Filtering:** normally better but may have the cold-start problem\n",
    "1. **Content-based Filtering:** higher availability of rating suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your setup\n",
    "import os\n",
    "import re\n",
    "import hashlib # for grading purposes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.sparse import csr_matrix, triu, coo_matrix\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q0 - Setup (non-graded)\n",
    "\n",
    "The first step is to import and analyze the data (in `data/ml-latest-small`).\n",
    "\n",
    "For these exercises, we'll be using a standard dataset for recommendations, called the [MovieLens](https://grouplens.org/datasets/movielens/) dataset. We'll be using the smallest version of the dataset.\n",
    "\n",
    "Small: 100,000 ratings and 3,600 tag applications applied to 9,000 movies by 600 users. Last updated 9/2018.\n",
    "\n",
    "We have three data files:\n",
    "* `ratings.csv`: has 100k ratings of 9k movies by 600 users\n",
    "* `movies.csv`: has the movieId, title and genre for 9k movies\n",
    "* `tags.csv`: has 3.6k tags applied to 9k movies by 600 users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_ratings_list(path):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : filepath of the ratings file to import\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    all_ratings : DataFrame of the ratings.\n",
    "    \"\"\"\n",
    "    all_ratings = pd.read_csv(path)\n",
    "    return all_ratings\n",
    "\n",
    "all_ratings = import_ratings_list(os.path.join(\"data\", \"ml-latest-small\", \"ratings.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"In total we have {len(all_ratings)} ratings available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a glimpse of the all_ratings DataFrame\n",
    "all_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_movies_details(path):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : filepath of the movies file to import\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    movies_df : DataFrame of the movies details\n",
    "    \"\"\"\n",
    "    return pd.read_csv(path).set_index(\"movieId\")\n",
    "\n",
    "movies_df = import_movies_details(os.path.join(\"data\", \"ml-latest-small\", \"movies.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1 - Add new Preferences\n",
    "\n",
    "So, imagine you've just created a Netflix account.\n",
    "In the setup process, you're asked to rate some movies so that you have some data associated with your profile.\n",
    "\n",
    "To simulate this, we will add your movie preferences to the existing `all_ratings` DataFrame.\n",
    "\n",
    "Note: we will use predefined ratings (to evaluate the exercises), but in the end you can play with these initial ratings to test out the recommender system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_user_id is the maximum user id available plus one (because science).\n",
    "new_user_id = max(all_ratings[\"userId\"]) + 1\n",
    "\n",
    "\n",
    "preference_1 = {\"userId\": new_user_id,\n",
    "                \"movieId\": 1,          #Toy Story\n",
    "                \"rating\": 4.0,\n",
    "                \"timestamp\": 964982703}\n",
    "\n",
    "preference_2 = {\"userId\": new_user_id,\n",
    "                \"movieId\": 32,         #Twelve Monkeys\n",
    "                \"rating\": 4.5,\n",
    "                \"timestamp\": 964982931}\n",
    "\n",
    "preference_3 = {\"userId\": new_user_id,\n",
    "                \"movieId\": 33672,      #Lords of Dogtown\n",
    "                \"rating\": 2.5,\n",
    "                \"timestamp\": 964982224}\n",
    "\n",
    "new_preferences = [preference_1, preference_2, preference_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1209c8fa8eec74fc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def add_new_preferences(new_preferences, all_ratings):\n",
    "    \"\"\"\n",
    "    Add the new preferences to the existing all_ratings DataFrame.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    new_preferences : list\n",
    "                      A list of dicts containing the new preferences.\n",
    "                      \n",
    "    all_ratings : pd.DataFrame\n",
    "                  DataFrame containing all the ratings available.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    all_ratings_extended : pd.DataFrame\n",
    "                           Existing all_ratings DataFrame extended with the new_preferences.\n",
    "                           Keep the original structure of 4 columns and guarantee the index is correctly ordered.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "all_ratings_extended = add_new_preferences(new_preferences, all_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-772850ad26f9249f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "expected_hash = 'ba4b0c26c8e4a2dd240461d4891c265af433569d06cd61f18fdd2d429615e0d5'\n",
    "assert hashlib.sha256(str(all_ratings_extended.shape).encode()).hexdigest() == expected_hash\n",
    "\n",
    "expected_hash = 'b7a56873cd771f2c446d369b649430b65a756ba278ff97ec81bb6f55b2e73569'\n",
    "test_value = str(int(all_ratings_extended.tail().iloc[-1][\"rating\"] * 10))\n",
    "assert hashlib.sha256(test_value.encode()).hexdigest() == expected_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2 - Build the Ratings Matrix\n",
    "\n",
    "Based on the ratings data, create the ratings matrix. This should follow the format adopted in the Learning Notebooks: rows are users, columns are items, and ratings are the matrix values.\n",
    "\n",
    "Note that the `userId=1` will be represented in the row with index `0`. And the same for items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-73eacf1225425c60",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def create_ratings_matrix(all_ratings_extended):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    all_ratings_extended : pd.DataFrame\n",
    "                           DataFrame with the original ratings list plus the new preferences defined above.\n",
    "                   \n",
    "    Returns\n",
    "    -------\n",
    "    ratings : csr_matrix\n",
    "              DataFrame with the ratings matrix. Index should be sorted.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "ratings = create_ratings_matrix(all_ratings_extended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-a027a752832fa141",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "expected_hash = '1b25bb37050096f8d9533f5c295f77a2705db79def84cccabbdc97db9dd34ef5'\n",
    "assert hashlib.sha256(str(ratings.shape).encode()).hexdigest() == expected_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-ba7f191b7dce2e95",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "availability = ratings.nnz / (ratings.shape[0] * ratings.shape[1])\n",
    "np.testing.assert_approx_equal(availability, 0.01697, significant=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Our ratings matrix has now {ratings.shape[0]} users and {ratings.shape[1]} items.\")\n",
    "print(f\"Our availability of ratings is {round(availability*100, 2)}% of the total!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Q3 - User Similarities\n",
    "\n",
    "Now that we have the ratings matrix already built, let's check some similarities.\n",
    "\n",
    "\n",
    "## Q3.1 - Overall User Similarities\n",
    "\n",
    "Get the similarities between users using the cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7ba0f4b6ac6e6c79",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_users_cosine_similarity(ratings):\n",
    "    \"\"\"\n",
    "    Get the cosine similarity between users.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ratings : csr_matrix\n",
    "              Ratings matrix.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    users_similarities : csr_matrix\n",
    "                        sparse representaion of the cosine similarity between users.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "users_similarities = get_users_cosine_similarity(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-845a9a541f4e82d1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "expected_hash = '8cde0a5542e6a6e1551ffbd9a804edabe20b546a4c3dbdd870ee4a478eed3efe'\n",
    "assert hashlib.sha256(str(users_similarities.shape).encode()).hexdigest() == expected_hash\n",
    "\n",
    "expected_hash = '46e0bd98d1e6c6519f99e2a20f74425f2ecc53e654bdb68182663dbf19271f63'\n",
    "assert hashlib.sha256(str(users_similarities.nnz).encode()).hexdigest() == expected_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3.2 - What is the nearest neighbor of our newly added user?\n",
    "\n",
    "Here we want to find the existing user who is the most similar to the newly added user.\n",
    "Return the index of the nearest neighbor user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-cbf93a8d2861a14a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_closest_user_index(users_similarities):\n",
    "    \"\"\"\n",
    "    Return the index of the closest user to the newly added user.\n",
    "    Hint: since the newly added user had the highest userId, they will be at the last row/column of\n",
    "    the similarities matrix.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    users_similarities : csr_matrix\n",
    "                         Cosine similarity between users matrix.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    closest_user_index : int\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "closest_user_index = get_closest_user_index(users_similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-fcf1a359253285eb",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "expected_hash = 'bd3a797ba948938978965781bd341bc0fc7711ed00e513b9c63a61cf3d916562'\n",
    "assert hashlib.sha256(str(closest_user_index).encode()).hexdigest() == expected_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3.3 - Compare the preferences of these two users (non-graded)\n",
    "\n",
    "Now that we have the index of our nearest neighbor user, let's check if the preferences of these two users are in fact, similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_with_new_user(all_ratings, userId, new_preferences):\n",
    "    \"\"\"\n",
    "    Compare a userId ratings with the ones we have in the new preferences.\n",
    "    Remeber that the userId must be the index of the users in the matrix plus 1, since the python index is 0-based\n",
    "    and our Ids are pegged to 1.\n",
    "    \"\"\"\n",
    "    moviesIds = [x[\"movieId\"] for x in new_preferences]\n",
    "    comparable_ratings = all_ratings[all_ratings[\"userId\"] == userId]\n",
    "    comparable_ratings = comparable_ratings[comparable_ratings[\"movieId\"].isin(moviesIds)]\n",
    "    return comparable_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"New user's preferences\")\n",
    "pd.DataFrame(new_preferences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Nearest neighbor's preferences\")\n",
    "compare_with_new_user(all_ratings, closest_user_index+1, new_preferences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3.4 - Get Users Predictions\n",
    "To make the predictions using only the users, you can leverage what you know about the true ratings (`ratings` matrix) and the similarity between the users previously calculated (`users_similarities`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4b927f9157112c21",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def make_user_predictions(user_sims, R):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    user_sims : csr_matrix, shape: (n_users, n_users)\n",
    "                Matrix with the similarities between users.\n",
    "    \n",
    "    R : csr_matrix, shape: (n_users, n_items)\n",
    "        Matrix with the available ratings.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    users_predictions : csr_matrix, shape: (n_users, n_items)\n",
    "                        Ratings predictions.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "users_predictions = make_user_predictions(users_similarities, ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-65508521973c7fee",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "expected_hash = '1b25bb37050096f8d9533f5c295f77a2705db79def84cccabbdc97db9dd34ef5'\n",
    "assert hashlib.sha256(str(users_predictions.shape).encode()).hexdigest() == expected_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-23c301075b3d4c00",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "np.testing.assert_almost_equal(users_predictions[-1, 1], 0.7765, decimal=4)\n",
    "np.testing.assert_almost_equal(users_predictions[-1].toarray()[0, 3000], 0.0526, decimal=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4 - Content-based Filtering\n",
    "Now let's move to predict based on the characteristics of the items themselves.\n",
    "\n",
    "We already imported the `movies_df` DataFrame, we just need to preprocess it a bit.\n",
    "\n",
    "We also have the tags file `tags.csv`that we can use. Since we have multiple tags for the same movie, we will join them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_tags_file(path):\n",
    "    df = pd.read_csv(path)                             # Import the DataFrame\n",
    "    df = df [[\"movieId\", \"tag\"]]                       # Select relevant features\n",
    "    df = df.set_index(\"movieId\")                       # Set movieId as the index\n",
    "    df[\"tag\"] = df[\"tag\"].str.replace(\" \", \"\")         # Remove the whitespaces for multi-word tags\n",
    "    df[\"tag\"] = df[\"tag\"].str.lower()                  # Lowercase all the genres for the sake of uniformity\n",
    "\n",
    "    return df\n",
    "\n",
    "tags_df = import_tags_file(os.path.join(\"data\", \"ml-latest-small\", \"tags.csv\"))\n",
    "tags_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4.1  - Preprocessing the contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the preprocessing step will have several steps, we will do what each programmer must do when facing complex tasks: *divide into multiple digestible understandble chunks of work*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4.1.1 - Preprocessing the Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6394b2a5662fff0d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_tags(tags_df):\n",
    "    \"\"\"\n",
    "    1st step of preprocessing the movies contents.\n",
    "    Join the multiple tags in a single row for each movie, with the tags separated by pipes and their whitespaces removed.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    tags_df : pd.DataFrame\n",
    "              Original dataframe for the tags\n",
    "              \n",
    "    Returns\n",
    "    -------\n",
    "    preprocessed_tags : pd.Series\n",
    "                        Series with movieId as Index and the multiple tags without whitespaces pipe-separated.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "preprocessed_tags = preprocess_tags(tags_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-81574ffe73d3be48",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "expected_hash = '9a7537a814317708c2e672111fd17f6a117a932ebdff5584bbedd67152396a7b'\n",
    "assert hashlib.sha256(str(preprocessed_tags.shape).encode()).hexdigest() == expected_hash\n",
    "\n",
    "assert isinstance(preprocessed_tags, pd.Series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4.1.2 - Join the Movies with the Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-dbf862ffa00ccdd4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def join_movies_with_tags(movies_df, tags_df):\n",
    "    \"\"\"\n",
    "    2nd step of preprocessing the movie contents.\n",
    "    Join the new tags obtained onto the movies_df.\n",
    "    CAUTION: Since we will not have tags for all the movies, just fill the missing ones with empty strings.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    movies_df : pd.DataFrame\n",
    "    \n",
    "    tags_df : pd.DataFrame\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    movies_with_tags : pd.DataFrame\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    \n",
    "movies_with_tags = join_movies_with_tags(movies_df, preprocessed_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-e0a7a28284e623e0",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "expected_hash = '4e07408562bedb8b60ce05c1decfe3ad16b72230967de01f640b7e4729b49fce'\n",
    "assert hashlib.sha256(str(len(movies_with_tags.columns)).encode()).hexdigest() == expected_hash\n",
    "\n",
    "assert isinstance(movies_with_tags, pd.DataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4.1.3 - Preprocessing the Movies Contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9c992405479ec2f9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_movies(movies_df, tags_df):\n",
    "    \"\"\"\n",
    "    Get the \"Description\" column by joining the genres, the tags and the year (separated by pipes \"|\").\n",
    "    Remove the year from the title and add it as a feature.\n",
    "    This \"Description\" column will be used for the TF-IDF.\n",
    "    \n",
    "    Steps needed:\n",
    "    1. Get the tags. Preprocess their content to have multiple pipe-separated tabs for each movie.\n",
    "    2. Join the movies_df with the new preprocessed_tags.\n",
    "    3. Get the year as a feature. Clean the text in the \"title\" feature and add the year as a new \"year\" feature.\n",
    "    4. Create a new \"Description\" feature with \"genres\", \"tag\" and \"year\" features. Join them with a pipe \"|\".\n",
    "    \n",
    "    You can use the functions \"preprocess_tags\" and \"join_movies_with_tags\" as defined above.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    movies_df : pd.DataFrame\n",
    "                original movies dataframe\n",
    "                \n",
    "    tags_df : pd.DataFrame\n",
    "              contains the tags as imported above\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    preprocessed_movies : pd.DataFrame, shape: (n_items, 1)\n",
    "                          Movies DataFrame preprocessed with both tags and genres ready to be TF-IDF Vectorized.\n",
    "    \"\"\"\n",
    "    preprocessed_tags = preprocess_tags(tags_df)\n",
    "    preprocessed_movies = join_movies_with_tags(movies_df, preprocessed_tags)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return preprocessed_movies[[\"Description\"]]\n",
    "\n",
    "preprocessed_movies = preprocess_movies(movies_df, tags_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-6b5ecfc3945fff0c",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "expected_hash = '4c59be6c9b0a96e2ead911ccca3567ac875d14038d9a420c100cb9fe6a0f17d3'\n",
    "assert hashlib.sha256(str(preprocessed_movies.shape).encode()).hexdigest() == expected_hash\n",
    "\n",
    "expected_hash = 'b0b9c775e3458ac9f26a530294be6feade98ba4ee2848dacbbec1e23a925b972'\n",
    "string = preprocessed_movies.loc[1][\"Description\"].replace('|', ',').lower()\n",
    "tokens = re.split(',',string)\n",
    "tokens.sort()\n",
    "assert hashlib.sha256(str(tokens).encode()).hexdigest() == expected_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a glimpse of the preprocessed movies\n",
    "preprocessed_movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4.2 - Matching the Contents\n",
    "### Matching variables (non-graded)\n",
    "\n",
    "After preprocessing the content for the movies (items), we need to match them to the original ratings listing we have already. To do this we match the index of our `preprocessed_movies` DataFrame (already unique) with the unique items we have in our original listing of ratings `all_ratings_extended`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(np.array(preprocessed_movies.index) == np.unique(all_ratings_extended[\"movieId\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    ".... and VOIL√Å! They don't match! üò° Let's check their sizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Preprocessed Movies index has {preprocessed_movies.index.shape[0]} elements\")\n",
    "print(f\"Original Ratings listing has {ratings.shape[1]} elements\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have more movieIds in the tags than in the ratings matrix, we need to subset the original `preprocessed_movies` DataFrame to only include the movies for which we have ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-546bddcb80dd9098",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def reduce_preprocessed_movies_scope(preprocessed_movies, all_ratings_extended):\n",
    "    \"\"\"\n",
    "    Filter out the movies that have information but that are not present in the original ratings listing.\n",
    "    \n",
    "    Tips and tricks:\n",
    "    Get the unique movieIds for the original listing (the index for preprocessed_movies should already be unique).\n",
    "    Get the movies for which we have the tags but not the ratings.\n",
    "    Select the movies in the preprocessed_movies which are not in the above.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    preprocessed_movies : pd.DataFrame\n",
    "                          DataFrame with the Description for all the movies available with tags.\n",
    "                          \n",
    "    all_ratings_extended : pd.DataFrame\n",
    "                           Listing of all the ratings available.\n",
    "                          \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    filtered_preprocessed_movies : pd.DataFrame\n",
    "                                   \n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "filtered_preprocessed_movies = reduce_preprocessed_movies_scope(preprocessed_movies, all_ratings_extended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-747f2faa877fd37f",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "expected_hash = 'f46df9a8f5e1c4c1f0e17649a4214e19503569f77991533f1db1747b28523fe5'\n",
    "assert hashlib.sha256(str(len(filtered_preprocessed_movies.index)).encode()).hexdigest() == expected_hash\n",
    "\n",
    "assert np.all(np.array(filtered_preprocessed_movies.index) == np.unique(all_ratings_extended[\"movieId\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4.3 - Calculate the Profiles for the Items\n",
    "Now that we have the attributes for each item (pipe-separated items present in the `filtered_preprocessed_movies`), we can calculate the item profiles for each item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-810408e9f169b757",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_item_profiles(preprocessed_movies: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Call a fit_transform on a TF-IDF Vectorizer.\n",
    "    Returns the profiles for the items.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    item_profiles : csr_matrix, shape: (n_items, n_tfidf_features)\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "item_profiles = get_item_profiles(filtered_preprocessed_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-7eb3dd58d39e1ff2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "expected_hash = 'a05c961fb42c746751e14ecf45ba31de109eb9bb60189057420399648931e823'\n",
    "assert hashlib.sha256(str(item_profiles.shape).encode()).hexdigest() == expected_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4.4 - User Profiles\n",
    "Next to step is to check that we have a *(n_users, n_items)* ratings matrix and a *(n_items, n_tfidf_features)*. If we multiply them, we get *(n_users, n_tfidf_features)*. \n",
    "\n",
    "Did we just associated the users with the item features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-20bcd68441488e85",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-f116d0e36809b9e6",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "expected_hash = '7bbb7fa14ce2f1a245bb1ce66f76292520aff0a9c043d054256c4b31706e366b'\n",
    "assert hashlib.sha256(str(user_profiles.shape).encode()).hexdigest() == expected_hash\n",
    "\n",
    "expected_hash = '228d8eceeba4d7d8764a521b0c9fb0d50d5010f74375960af5ca62203a6dcb17'\n",
    "assert hashlib.sha256(str(user_profiles.nnz).encode()).hexdigest() == expected_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4.5 - The Moment of Truth\n",
    "We will do what recommender systems should do: recommend. (mind-blowing, right?!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5ac2689623d9a18c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def make_predictions(R, item_profiles, user_profiles):\n",
    "    \"\"\"\n",
    "    Make predictions based on the ratings matrix, the item profiles and the user profiles we calculated previously.\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    R : csr_matrix. shape: (n_users, n_items)\n",
    "        Matrix containing the ratings initially assigned.\n",
    "        \n",
    "    item_profiles : csr_matrix. shape: (n_items, n_tfidf_features)\n",
    "                    Matrix containing the TF-IDF features calculated for the items.\n",
    "                    \n",
    "    user_profiles : csr_matrix. shape: (n_users, n_tfidf_features)\n",
    "                    Matrix containing the user profiles as the product of the ratings with the item profiles.\n",
    "                    \n",
    "                    \n",
    "    Returns\n",
    "    -------\n",
    "    predictions : csr_matrix. shape: (n_users, n_items)\n",
    "                  Matrix with the predictions. Already rated content is suppressed to 0.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "\n",
    "pred = make_predictions(ratings, item_profiles, user_profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-5f6533735e4c9cc1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(pred, csr_matrix)\n",
    "assert pred.shape == ratings.shape # Your predictions shape should match the original ratings matrixa\n",
    "np.testing.assert_almost_equal(pred[-1, 200], 0.06885, decimal=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4.5 Get Top-7 items for each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f7dc7173198255e6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_top_n(pred, n=3):\n",
    "    \"\"\"\n",
    "    Calculates the sorted best n items for each user.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    pred : csr_matrix, shape: (n_users, n_items)\n",
    "           Matrix with predictions for the items.\n",
    "           \n",
    "    n : int\n",
    "        Top-n items for each user. Default to 3.\n",
    "        \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    best_preds : np.ndarray, shape: (n_users, n)\n",
    "                 Sorted n-best items for each user.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "best_preds = get_top_n(pred, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-0f069497bddd5576",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "expected_hash = 'c103df72e15cf510fd1acdd2fa2e71fdb7fb3ebf72441fd79d8aa1bee87169fd'\n",
    "assert hashlib.sha256(str(best_preds[50, 5]).encode()).hexdigest() == expected_hash\n",
    "\n",
    "expected_hash = 'd6420a4ee44bc345c7bf3a2efbab98e08a4727016df8e8d6bb8375d0a23a8c72'\n",
    "assert hashlib.sha256(str(best_preds[-1, 6]).encode()).hexdigest() == expected_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5 - New User's Best Predictions (non-graded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"The Top-7 items for the user are indexed as {list(best_preds[-1])}\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
