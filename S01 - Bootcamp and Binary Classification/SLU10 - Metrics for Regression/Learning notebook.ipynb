{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLU10 - Metrics for regression: Learning Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you will learn about:\n",
    "    - Loss functions vs. Evaluation Metrics\n",
    "    - Mean Absolute Error (MAE)\n",
    "    - Mean Squared Error (MSE)\n",
    "    - Root Mean Squared Error (RMSE)\n",
    "    - Coefficient of Determination (R²)\n",
    "    - Adjusted R²\n",
    "    - Scikitlearn metrics\n",
    "    - Using metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In SLU07, you were introduced to one of the most intuitive and used regression models. You were also introduced to function ($J$) that measured how good the linear regression model was. In this SLU, we will take a look at that function, and others, more in-depth. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Loss functions vs. Evaluation Metrics\n",
    "\n",
    "Before we dig into the metrics, there is something we should make it clear first. It will be very usual, while studying & practising data science, that you will hear/read these two words: **loss** and **metric**. Both of them refer to functions that evaluate the **quality** of a model. Sometimes, people will use both as they are the same thing. But really important differences between them:\n",
    "* **Loss** is the function that your model will minimize;\n",
    "* **Metric** is the function that you really want to use to evaluate how good your model is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, the loss and metric functions are the same (example: linear regression). But other times, e.g. in classification, the metric will be really different from the loss. In this notebook,  **we will focus on metrics**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Metrics for Linear Regression\n",
    "\n",
    "### 2.1 - Mean Absolute Error (MAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$MAE = \\frac{1}{N} \\sum_{n=1}^N \\left|y_n - \\hat{y}_n\\right|$$\n",
    "\n",
    "where $N$ is the number of observations in your dataset, $y_n$ is the target and $\\hat{y}_n$ is the prediction given the observation $x_n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = lambda y, y_hat: np.abs(y - y_hat).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The lower, the better.\n",
    "* It is less sensible to outliers than MSE (the next metric).\n",
    "* The output can be interpreted as the expected error measured in the same units as the target.\n",
    "* It can be used as both a metric and a loss function. There are some important caveats to take into consideration when using MAE as a loss function: (a) the number of solutions, (b) large jumps in the values of the parameters and (c) not having a derivative when MAE is 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - Mean Squared Error (MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In SLU07, we already explored this metric\n",
    "\n",
    "$$MSE = \\frac{1}{N} \\sum_{n=1}^N (y_n - \\hat{y}_n)^2$$\n",
    "\n",
    "where $N$ is the number of observations in your dataset, $y_n$ is the target and $\\hat{y}_n$ is the prediction given the observation $x_n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = lambda y, y_hat: ((y - y_hat)**2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The lower, the better.\n",
    "* MSE can be used as both a metric and a loss function (e.g. linear regression).\n",
    "* It is sensible to outliers in its' original form.\n",
    "* The units of the metric are not the same as the ones used in the target. For example, if you are predicting house prices, i.e. the output is \\$, then the output would have units like \\$²."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 - Root Mean Squared Error (RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$RMSE = \\sqrt{MSE}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = lambda y, y_hat: np.sqrt(mse(y, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The lower, the better.\n",
    "* Its' output can be interpreted as having the same units as the targets.\n",
    "* MSE can be used as both a metric and a loss function. If fact, if we computed its partial derivative is $\\frac{\\partial RMSE}{\\partial \\hat{y}} = \\frac{1}{2 \\sqrt{MSE}} MSE$\n",
    "* Similar to MSE, RMSE will also be sensitive to outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 - Coefficient of Determination (R²)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R² compares how better your regression model is when compared with a predictor that outputs just the mean of the targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\bar{y} = \\frac{1}{N} \\sum_{n=1}^N y_n$$\n",
    "\n",
    "$$R² = 1 - \\frac{MSE(y, \\hat{y})}{MSE(y, \\bar{y})} \n",
    "= 1 - \\frac{\\frac{1}{N} \\sum_{n=1}^N (y_n - \\hat{y}_n)^2}{\\frac{1}{N} \\sum_{n=1}^N (y_n - \\bar{y})^2}\n",
    "= 1 - \\frac{\\sum_{n=1}^N (y_n - \\hat{y}_n)^2}{\\sum_{n=1}^N (y_n - \\bar{y})^2}$$\n",
    "\n",
    "where $N$ is the number of observations in your dataset, $y_n$ is the target and $\\hat{y}_n$ is the prediction given the observation $x_n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = lambda y, y_hat: 1 - (mse(y, y_hat) / mse(y, np.mean(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The higher the R², the more sure you are that the independent variables you used explain how the dependent variable changes. For example, if you got a R² of 0.7, you can say that the set of features you used are able to explain 70% of the target variable..\n",
    "\n",
    "The higher R² you can get is 1. If you get R² = 0, it means that your model doesn't explain anything in the target by using the features you selected. If you get R² < 0, you are probably suffering too much with overshooting. Also, another reason for having R² < 0 is that the model you used doesn't make sense for that data you have.\n",
    "\n",
    "Also, when using R², there are something important [caveats](https://en.wikipedia.org/wiki/Coefficient_of_determination#Caveats) to take into account. One of the caveats is that, depending on the model, using more features can inflate the R² when, in fact, those features are really noisy, meaning the model is actually fitting to the noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 - Adjusted R²"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to take into account the addition of useless variables, we can use the adjusted R² score\n",
    "\n",
    "$$R_{adj}^2 = 1 - \\frac{N - 1}{N - K - 1} (1 - R^2)$$\n",
    "\n",
    "where $N$ is the number of observations in the training dataset and K is the number of features your model is using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_r2 = lambda y, y_hat, N, K: 1 - ((N - 1) / (N - K - 1)) * (1 - r2(y, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Using the metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you learned in previous units, there are many ways of selecting your best estimator, and most of it relies on some way of measuring an in-sample-error (ISE) - computed on data used for training - and an out-of-sample error (OSE) - compute on data not used for training. \n",
    "\n",
    "### 3.1 - Hold out method\n",
    "\n",
    "One of the methods you've seen were the hold-out method, where you can just split your data in a training set, where we will compoute the ISE, and a test set, where we will compute the OSE.\n",
    "\n",
    "Let's start by seeing how to use this method with different metrics. First, let's load some data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1158e90b8>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv('data/linear-learning.csv')\n",
    "df = df.sort_values('x')\n",
    "\n",
    "x = df['x'].values\n",
    "y = df['y'].values\n",
    "\n",
    "plt.plot(x, y, 'r.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, remember the sklearn function to get your split for the hold-out method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations:\n",
      "Train: 30 | Test: 20\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.4)\n",
    "print(\"Number of observations:\\nTrain: {} | Test: {}\".format(x_train.shape[0], x_test.shape[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to train some classifiers and get estimates on both the training data and the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "x_train_clf = x_train.reshape(-1, 1)\n",
    "x_test_clf = x_test.reshape(-1, 1)\n",
    "\n",
    "clf_1 = linear_model.LinearRegression()\n",
    "clf_2 = linear_model.SGDRegressor()\n",
    "\n",
    "clf_1.fit(x_train_clf, y_train)\n",
    "clf_2.fit(x_train_clf, y_train)\n",
    "\n",
    "y_hat_train_1 = clf_1.predict(x_train_clf)\n",
    "y_hat_train_2 = clf_2.predict(x_train_clf)\n",
    "\n",
    "y_hat_test_1 = clf_1.predict(x_test_clf)\n",
    "y_hat_test_2 = clf_2.predict(x_test_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we want to compare the metrics on both test sets. Let's see use one of our metrics results for these estimators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE)\n",
      "LinearRegression estimator ISE with MAE: 1.785580545485204\n",
      "SGDRegressor estimator ISE with MAE: 1.8006038932953492\n",
      "LinearRegression estimator OSE with MAE: 1.6664668327322623\n",
      "SGDRegressor estimator OSE with MAE: 1.5520183262971372\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean Absolute Error (MAE)\")\n",
    "print(\"LinearRegression estimator ISE with MAE: {}\".format(mae(y_train, y_hat_train_1)))\n",
    "print(\"SGDRegressor estimator ISE with MAE: {}\".format(mae(y_train, y_hat_train_2)))\n",
    "print(\"LinearRegression estimator OSE with MAE: {}\".format(mae(y_test, y_hat_test_1)))\n",
    "print(\"SGDRegressor estimator OSE with MAE: {}\".format(mae(y_test, y_hat_test_2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, using this metric, the SGDRegressor seems to perform better in unseen examples. Try out below for other metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE)\n",
      "LinearRegression estimator ISE with MSE: 4.552729667690825\n",
      "SGDRegressor estimator ISE with MSE: 4.6182720629585585\n",
      "LinearRegression estimator OSE with MSE: 4.17228029434453\n",
      "SGDRegressor estimator OSE with MSE: 3.680779526800562\n",
      "\n",
      "========================\n",
      "\n",
      "Root Mean Squared Error (RMSE)\n",
      "LinearRegression estimator ISE with RMSE: 2.133712648809775\n",
      "SGDRegressor estimator ISE with RMSE: 2.149016533896042\n",
      "LinearRegression estimator OSE with RMSE: 2.0426160418308013\n",
      "SGDRegressor estimator OSE with RMSE: 1.918535776784098\n",
      "\n",
      "========================\n",
      "\n",
      "R Squared (R2)\n",
      "LinearRegression estimator ISE with R2: 0.8788698193047504\n",
      "SGDRegressor estimator ISE with R2: 0.8771259946629489\n",
      "LinearRegression estimator OSE with R2: 0.9227062273372492\n",
      "SGDRegressor estimator OSE with R2: 0.9318115476681018\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean Squared Error (MSE)\")\n",
    "print(\"LinearRegression estimator ISE with MSE: {}\".format(mse(y_train, y_hat_train_1)))\n",
    "print(\"SGDRegressor estimator ISE with MSE: {}\".format(mse(y_train, y_hat_train_2)))\n",
    "print(\"LinearRegression estimator OSE with MSE: {}\".format(mse(y_test, y_hat_test_1)))\n",
    "print(\"SGDRegressor estimator OSE with MSE: {}\".format(mse(y_test, y_hat_test_2)))\n",
    "\n",
    "print(\"\\n========================\\n\")\n",
    "\n",
    "print(\"Root Mean Squared Error (RMSE)\")\n",
    "print(\"LinearRegression estimator ISE with RMSE: {}\".format(rmse(y_train, y_hat_train_1)))\n",
    "print(\"SGDRegressor estimator ISE with RMSE: {}\".format(rmse(y_train, y_hat_train_2)))\n",
    "print(\"LinearRegression estimator OSE with RMSE: {}\".format(rmse(y_test, y_hat_test_1)))\n",
    "print(\"SGDRegressor estimator OSE with RMSE: {}\".format(rmse(y_test, y_hat_test_2)))\n",
    "\n",
    "print(\"\\n========================\\n\")\n",
    "\n",
    "print(\"R Squared (R2)\")\n",
    "print(\"LinearRegression estimator ISE with R2: {}\".format(r2(y_train, y_hat_train_1)))\n",
    "print(\"SGDRegressor estimator ISE with R2: {}\".format(r2(y_train, y_hat_train_2)))\n",
    "print(\"LinearRegression estimator OSE with R2: {}\".format(r2(y_test, y_hat_test_1)))\n",
    "print(\"SGDRegressor estimator OSE with R2: {}\".format(r2(y_test, y_hat_test_2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that to analyze it, you need to know if our metric should be minimized (like MSE) or maximized (like R2). If you want to normalize this to make sure your implementation is able to pick a model you can simply impose that your metric should be maximized, for example, and just reverse metrics that don't fit this definition.\n",
    "\n",
    "For example, we can turn MSE into negative MSE and apply the same behavior to other metrics that aim to be minimized. That way, we could write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegressor estimator ISE with Negative MAE: -1.785580545485204\n",
      "LinearRegressor estimator OSE with Negative MAE: -1.6664668327322623\n",
      "SGDRegressor estimator ISE with Negative MAE: -1.7674108869984027\n",
      "SGDRegressor estimator OSE with Negative MAE: -1.7826813151943472\n",
      "\n",
      "Best model with Negative MAE: LinearRegressor\n",
      "\n",
      "========================\n",
      "\n",
      "LinearRegressor estimator ISE with Negative MSE: -4.552729667690825\n",
      "LinearRegressor estimator OSE with Negative MSE: -4.17228029434453\n",
      "SGDRegressor estimator ISE with Negative MSE: -4.606215315965559\n",
      "SGDRegressor estimator OSE with Negative MSE: -4.614274402597188\n",
      "\n",
      "Best model with Negative MSE: LinearRegressor\n",
      "\n",
      "========================\n",
      "\n",
      "LinearRegressor estimator ISE with Negative RMSE: -2.133712648809775\n",
      "LinearRegressor estimator OSE with Negative RMSE: -2.0426160418308013\n",
      "SGDRegressor estimator ISE with Negative RMSE: -2.1462095228484936\n",
      "SGDRegressor estimator OSE with Negative RMSE: -2.1480862186134866\n",
      "\n",
      "Best model with Negative RMSE: LinearRegressor\n",
      "\n",
      "========================\n",
      "\n",
      "LinearRegressor estimator ISE with R2: 0.8788698193047504\n",
      "LinearRegressor estimator OSE with R2: 0.9227062273372492\n",
      "SGDRegressor estimator ISE with R2: 0.8774467771491622\n",
      "SGDRegressor estimator OSE with R2: 0.9145180449258555\n",
      "\n",
      "Best model with R2: LinearRegressor\n",
      "\n",
      "========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mae_mod = lambda y, y_hat: -mae(y, y_hat)\n",
    "mse_mod = lambda y, y_hat: -mse(y, y_hat)\n",
    "rmse_mod = lambda y, y_hat: -rmse(y, y_hat)\n",
    "\n",
    "metrics = {\n",
    "    'Negative MAE': mae_mod,\n",
    "    'Negative MSE': mse_mod,\n",
    "    'Negative RMSE': rmse_mod,\n",
    "    'R2': r2\n",
    "}\n",
    "\n",
    "clfs = {\n",
    "    'LinearRegressor': clf_1,\n",
    "    'SGDRegressor': clf_2\n",
    "}\n",
    "\n",
    "\n",
    "for key, clf in clfs.items():\n",
    "    clf.fit(x_train_clf, y_train)\n",
    "\n",
    "for metric, metric_f in metrics.items():\n",
    "    \n",
    "    best = None \n",
    "    best_model = None\n",
    "    for key, clf in clfs.items():\n",
    "        y_hat_train = clf.predict(x_train_clf)\n",
    "        y_hat_test = clf.predict(x_test_clf)\n",
    "\n",
    "        train_score = metric_f(y_train, y_hat_train)\n",
    "        test_score = metric_f(y_test, y_hat_test)\n",
    "        print(\"{} estimator ISE with {}: {}\".format(key, metric, train_score))\n",
    "        print(\"{} estimator OSE with {}: {}\".format(key, metric, test_score))\n",
    "        if not best or test_score > best:\n",
    "            best = test_score\n",
    "            best_model = key\n",
    "\n",
    "    print(\"\\nBest model with {}: {}\".format(metric, best_model))\n",
    "        \n",
    "    print(\"\\n========================\\n\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see, it is quite usefull for all metrics to have the same logic in terms of performance, this is, how you should interpret if the model is better or not. We will see the same for cross-validation now.\n",
    "\n",
    "### 3.2 - K-fold cross validation\n",
    "\n",
    "Another of the methods you've seen is cross validation by using a division in train/test data K times and assessing the scores that come out of it. Let's use the same example and classifiers as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "\n",
    "df = pd.read_csv('data/linear-learning.csv')\n",
    "df = df.sort_values('x')\n",
    "\n",
    "x = df['x'].values\n",
    "y = df['y'].values\n",
    "\n",
    "x_clf = x.reshape(-1, 1)\n",
    "y_clf = y.reshape(-1, 1)\n",
    "\n",
    "clf_1 = linear_model.LinearRegression()\n",
    "clf_2 = linear_model.SGDRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With scikitlearn, you can run the `cross_val_score` with k-fold and output the scores in each fold for both estimators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: LinearRegressor\n",
      "Score avg. : 0.21504998280872875\n",
      "Estimator: SGDRegressor\n",
      "Score avg. : 0.2201391287155796\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "clfs = {\n",
    "    'LinearRegressor': clf_1,\n",
    "    'SGDRegressor': clf_2\n",
    "}\n",
    "\n",
    "for key, clf in clfs.items():\n",
    "    clf.fit(x_train_clf, y_train)\n",
    "\n",
    "    \n",
    "K = 5\n",
    "for key, clf in clfs.items():\n",
    "    scores = cross_val_score(clf, x_clf, y, cv=K)\n",
    "    print('Estimator: {}'.format(key))\n",
    "    print('Score avg. : {}'.format(scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what is this score? If the scoring method is not specified, the estimator scorer is used. For both of our estimators, in this particular case, this corresponds to the coefficient of determination R^2 of the prediction. \n",
    "\n",
    "But what if we want to use another metric? Actually, the `cross_val_score` gives us the possibility of doing so, by passing a `scoring` parameter, which can be a string, for example. You can check [here](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter) all of the possibilities, but for this SLU the most important one are:\n",
    "\n",
    "* `neg_mean_absolute_error`\tmetrics.explained_variance_score\t \n",
    "* `neg_mean_squared_error`\tmetrics.explained_variance_score\t \n",
    "* `r2`\tmetrics.explained_variance_score\n",
    "\n",
    "In this case, the metrics follow the rule of \"higher is better\", thus the negative MAE and MSE possibilities. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: LinearRegressor\n",
      "Negative MAE avg. : -1.7417523056701114\n",
      "Estimator: SGDRegressor\n",
      "Negative MAE avg. : -1.7396976447607582\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "clfs = {\n",
    "    'LinearRegressor': clf_1,\n",
    "    'SGDRegressor': clf_2\n",
    "}\n",
    "\n",
    "for key, clf in clfs.items():\n",
    "    clf.fit(x_train_clf, y_train)\n",
    "\n",
    "    \n",
    "K = 5\n",
    "for key, clf in clfs.items():\n",
    "    scores = cross_val_score(clf, x_clf, y, cv=K, scoring=\"neg_mean_absolute_error\")\n",
    "    print('Estimator: {}'.format(key))\n",
    "    print('Negative MAE avg. : {}'.format(scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also other ways of passing on metrics do these functions, and this is not the only function to perform these comparisons. You can explore the model selection to learn more about it. But for now, move forward to the exercises and the next SLUs.\n",
    "\n",
    "![goodbye](assets/goodbye.gif)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
